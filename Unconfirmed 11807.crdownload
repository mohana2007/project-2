# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fQa64a9qedREMe2UCMkBjjyukIqszrua
"""

Install required packages
!pip install pandas scikit-learn tensorflow
import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow import keras
from tensorflow.keras import layers
# Load the dataset from a public URL
url = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.data'
columns = ['user_id', 'movie_id', 'rating', 'timestamp']
df = pd.read_csv(url, sep='\t', names=columns)

df.head()
# Encode user_id and movie_id to integer index
user_ids = df['user_id'].unique().tolist()
movie_ids = df['movie_id'].unique().tolist()

user2user_encoded = {x: i for i, x in enumerate(user_ids)}
movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}

df['user'] = df['user_id'].map(user2user_encoded)
df['movie'] = df['movie_id'].map(movie2movie_encoded)

num_users = len(user2user_encoded)
num_movies = len(movie2movie_encoded)

df['rating'] = df['rating'].values.astype(np.float32)

# Split dataset
x = df[['user', 'movie']].values
y = df['rating'].values

x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)
# Define the model
embedding_size = 50

user_input = keras.Input(shape=(1,))
user_embedding = layers.Embedding(num_users, embedding_size)(user_input)
user_vec = layers.Flatten()(user_embedding)

movie_input = keras.Input(shape=(1,))
movie_embedding = layers.Embedding(num_movies, embedding_size)(movie_input)
movie_vec = layers.Flatten()(movie_embedding)

concat = layers.Concatenate()([user_vec, movie_vec])
dense = layers.Dense(128, activation='relu')(concat)
dense = layers.Dense(32, activation='relu')(dense)
output = layers.Dense(1)(dense)

model = keras.Model([user_input, movie_input], output)
model.compile(loss='mean_squared_error', optimizer='adam')
model.summary()
history = model.fit(
    [x_train[:, 0], x_train[:, 1]],
    y_train,
    validation_data=([x_val[:, 0], x_val[:, 1]], y_val),
    batch_size=64,
    epochs=5
)
def recommend_movies(user_id, model, df, movie2movie_encoded, user2user_encoded, num_recommendations=10):
    encoded_user_id = user2user_encoded[user_id]
    all_movie_ids = np.array(list(movie2movie_encoded.values()))

    user_array = np.array([encoded_user_id] * len(all_movie_ids))
    predictions = model.predict([user_array, all_movie_ids])

    movie_pred = list(zip(all_movie_ids, predictions.flatten()))
    movie_pred.sort(key=lambda x: x[1], reverse=True)

    reverse_movie_map = {v: k for k, v in movie2movie_encoded.items()}
    top_movie_ids = [reverse_movie_map[x[0]] for x in movie_pred[:num_recommendations]]

    return df[df['movie_id'].isin(top_movie_ids)][['movie_id']].drop_duplicates()

# Example usage:
recommend_movies(1, model, df, movie2movie_encoded, user2user_encode)d